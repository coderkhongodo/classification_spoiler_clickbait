# ğŸ“Š BÃ¡o cÃ¡o KhÃ¡m phÃ¡ Dá»¯ liá»‡u Clickbait Spoiler

## ğŸ¯ Tá»•ng quan Dataset

### ThÃ´ng tin cÆ¡ báº£n
- **Nguá»“n**: SemEval-2023 Clickbait Spoiling Dataset
- **Tá»•ng sá»‘ máº«u**: 4,000
- **Training set**: 3,200 máº«u (80%)
- **Validation set**: 800 máº«u (20%)

### Cáº¥u trÃºc dá»¯ liá»‡u
Dataset chá»©a 14 trÆ°á»ng thÃ´ng tin chÃ­nh:
- `uuid`: ID duy nháº¥t
- `postText`: Ná»™i dung clickbait post (list)
- `targetTitle`: TiÃªu Ä‘á» bÃ i viáº¿t gá»‘c
- `targetParagraphs`: Ná»™i dung bÃ i viáº¿t gá»‘c (list)
- `targetDescription`: MÃ´ táº£ bÃ i viáº¿t
- `targetKeywords`: Tá»« khÃ³a liÃªn quan
- `spoiler`: Spoiler text (list)
- `tags`: Loáº¡i spoiler (list)

## ğŸ“‹ PhÃ¢n tÃ­ch Loáº¡i Spoiler

### PhÃ¢n phá»‘i cÃ¡c loáº¡i spoiler:
1. **Phrase** (Cá»¥m tá»«): 1,367 máº«u (42.7%)
   - Spoiler ngáº¯n, thÆ°á»ng 1-3 tá»«
   - Äá»™ dÃ i trung bÃ¬nh: 2.5 tá»«
   - VÃ­ dá»¥: "2070", "intellectual stimulation"

2. **Passage** (Äoáº¡n vÄƒn): 1,274 máº«u (39.8%)
   - Spoiler dÃ i hÆ¡n, thÆ°á»ng lÃ  cÃ¢u hoáº·c Ä‘oáº¡n ngáº¯n
   - Äá»™ dÃ i trung bÃ¬nh: 21.2 tá»«
   - VÃ­ dá»¥: "how about that morning we go throw?"

3. **Multi** (Nhiá»u pháº§n): 559 máº«u (17.5%)
   - Spoiler phá»©c táº¡p nháº¥t, nhiá»u thÃ nh pháº§n
   - Äá»™ dÃ i trung bÃ¬nh: 29.1 tá»«
   - Äá»™ dÃ i cÃ³ thá»ƒ lÃªn Ä‘áº¿n 255 tá»«

### Insights:
- Dataset **tÆ°Æ¡ng Ä‘á»‘i cÃ¢n báº±ng** giá»¯a phrase vÃ  passage
- Multi class Ã­t hÆ¡n nhÆ°ng váº«n Ä‘á»§ Ä‘á»ƒ training
- **Imbalanced dataset** - cáº§n xem xÃ©t khi training classification model

## ğŸ“ PhÃ¢n tÃ­ch Äá»™ dÃ i VÄƒn báº£n

### Thá»‘ng kÃª chi tiáº¿t:

| TrÆ°á»ng | Trung bÃ¬nh | Trung vá»‹ | Min-Max | Äá»™ lá»‡ch chuáº©n |
|--------|------------|----------|---------|---------------|
| Post Text | 10.8 tá»« | 11.0 tá»« | 1-28 tá»« | 3.5 |
| Spoiler | 14.6 tá»« | 7.0 tá»« | 1-255 tá»« | 19.3 |
| Target Title | 11.3 tá»« | 11.0 tá»« | 0-33 tá»« | 3.5 |
| Target Paragraphs | 514.8 tá»« | 352.5 tá»« | 7-14,059 tá»« | 583.3 |

### Key Findings:
- **Post Text** ráº¥t ngáº¯n (trung bÃ¬nh 11 tá»«) - Ä‘áº·c trÆ°ng cá»§a clickbait
- **Target Paragraphs** ráº¥t dÃ i vÃ  cÃ³ Ä‘á»™ biáº¿n thiÃªn lá»›n
- **Spoiler length** cÃ³ phÃ¢n phá»‘i skewed (median < mean)
- **Target Title** tÆ°Æ¡ng tá»± Post Text vá» Ä‘á»™ dÃ i

## â“ PhÃ¢n tÃ­ch Dá»¯ liá»‡u Thiáº¿u

### Missing Values:
- **postText**: 0% (hoÃ n háº£o)
- **targetTitle**: 0.03% (1/3200 - negligible)
- **targetParagraphs**: 0% (hoÃ n háº£o)
- **targetDescription**: 10.4% (332/3200)
- **targetKeywords**: 41.1% (1314/3200)
- **spoiler**: 0% (hoÃ n háº£o)

### Implications:
- **targetKeywords** thiáº¿u nhiá»u nháº¥t - cáº§n xá»­ lÃ½ Ä‘áº·c biá»‡t
- **targetDescription** thiáº¿u Ã­t hÆ¡n nhÆ°ng váº«n Ä‘Ã¡ng ká»ƒ
- CÃ¡c trÆ°á»ng chÃ­nh (postText, spoiler, targetParagraphs) Ä‘áº§y Ä‘á»§

## ğŸ¯ PhÃ¢n tÃ­ch theo Task cá»¥ thá»ƒ

### Task 1: Spoiler Generation
**Input**: postText + targetParagraphs â†’ **Output**: spoiler

#### Thá»‘ng kÃª Input:
- **Äá»™ dÃ i trung bÃ¬nh**: 525.6 tá»«
- **â‰¤ 512 tokens**: 66.9% (cáº§n truncation cho 33.1%)
- **PhÃ¹ há»£p vá»›i GPT-2 max_length = 512**

#### Thá»‘ng kÃª Output:
- **Äá»™ dÃ i trung bÃ¬nh**: 14.6 tá»«
- **â‰¤ 128 tokens**: 99.6% (ráº¥t phÃ¹ há»£p)
- **Max target length = 128 lÃ  Ä‘á»§**

### Task 2: Spoiler Type Classification
**Features**: 5 text fields â†’ SBERT embeddings â†’ **Output**: spoiler type

#### Feature Analysis:
- **postText**: 10.8 tá»« (ngáº¯n, Ä‘áº·c trÆ°ng)
- **targetTitle**: 11.3 tá»« (tÆ°Æ¡ng tá»± postText)
- **targetParagraphs**: 514.8 tá»« (dÃ i nháº¥t, chá»©a nhiá»u thÃ´ng tin)
- **targetDescription**: 20.9 tá»« (trung bÃ¬nh)
- **targetKeywords**: 7.6 tá»« (ngáº¯n)

#### Embedding Strategy:
- **SBERT model**: all-MiniLM-L6-v2 (384 dimensions)
- **Combined features**: 384 Ã— 5 = 1,920 dimensions
- **Handle missing values** trong targetDescription vÃ  targetKeywords

## ğŸ’¡ Khuyáº¿n nghá»‹ Implementation

### Task 1 - Spoiler Generation:
1. **Model**: GPT-2 Medium fine-tuned
2. **Preprocessing**:
   - `max_input_length = 512` (cover 67% data, truncate rest)
   - `max_target_length = 128` (cover 99.6% data)
   - Combine postText + targetParagraphs as input
3. **Training**:
   - Learning rate: 5e-5
   - Batch size: 8 vá»›i gradient accumulation
   - Early stopping based on validation loss

### Task 2 - Spoiler Type Classification:
1. **Feature Engineering**:
   - Use SBERT Ä‘á»ƒ encode 5 text fields
   - Handle missing values:
     - targetDescription: fill vá»›i ""
     - targetKeywords: fill vá»›i ""
   - Concatenate embeddings â†’ 1920-dim vector

2. **Models to test**:
   - Naive Bayes, KNN, Decision Tree
   - AdaBoost, Logistic Regression
   - Gradient Boosting, Random Forest
   - **SVM** (expected best performer)

3. **Evaluation**:
   - Cross-validation vá»›i 5 folds
   - Metrics: Accuracy, Precision, Recall, F1, MCC
   - Handle class imbalance náº¿u cáº§n

### Data Preprocessing:
1. **Text cleaning**: Remove HTML, normalize whitespace
2. **Tokenization**: Sá»­ dá»¥ng GPT-2 tokenizer cho generation
3. **Missing value handling**: Strategy khÃ¡c nhau cho tá»«ng field
4. **Data splitting**: Maintain class distribution trong splits

## ğŸ“Š Biá»ƒu Ä‘á»“ Ä‘Æ°á»£c táº¡o

1. **spoiler_types_distribution.png**: PhÃ¢n phá»‘i loáº¡i spoiler
2. **text_length_distributions.png**: PhÃ¢n phá»‘i Ä‘á»™ dÃ i vÄƒn báº£n
3. **spoiler_analysis_by_type.png**: So sÃ¡nh spoiler theo loáº¡i
4. **missing_data_analysis.png**: PhÃ¢n tÃ­ch dá»¯ liá»‡u thiáº¿u
5. **task_specific_analysis.png**: PhÃ¢n tÃ­ch theo tá»«ng task

## ğŸ¯ Káº¿t luáº­n

Dataset SemEval-2023 Clickbait Spoiling cÃ³ cháº¥t lÆ°á»£ng tá»‘t vá»›i:
- âœ… **Dá»¯ liá»‡u Ä‘áº§y Ä‘á»§** cho cÃ¡c trÆ°á»ng chÃ­nh
- âœ… **PhÃ¢n phá»‘i há»£p lÃ½** giá»¯a cÃ¡c loáº¡i spoiler
- âœ… **Äá»™ dÃ i phÃ¹ há»£p** vá»›i cÃ¡c model hiá»‡n táº¡i
- âš ï¸ **Cáº§n xá»­ lÃ½** missing values trong targetKeywords
- âš ï¸ **Cáº§n truncation** cho input dÃ i trong generation task

Dataset sáºµn sÃ ng cho viá»‡c implement cáº£ hai task vá»›i cÃ¡c insights vÃ  khuyáº¿n nghá»‹ Ä‘Ã£ Ä‘Æ°á»£c Ä‘Æ°a ra. 