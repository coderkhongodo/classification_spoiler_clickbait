# ğŸ¯ Clickbait Spoiler Generation and Classification Research

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-Educational-green.svg)](LICENSE)
[![Research](https://img.shields.io/badge/Purpose-Academic%20Research-orange.svg)](README.md)
[![Status](https://img.shields.io/badge/Task%202-Completed%20âœ…-success.svg)](README.md)
[![Accuracy](https://img.shields.io/badge/Best%20Model-SVM%2085.5%25-brightgreen.svg)](README.md)

> **A research project on clickbait spoiler classification using SBERT + Machine Learning achieving **SVM 85.5% accuracy**.

## ğŸ“Š **Key Results Achieved**

| Metric | Random Forest | **SVM (Best)** | Logistic Regression |
|--------|---------------|----------------|-------------------|
| **Accuracy** | 82.50% | **ğŸ† 85.50%** | 81.87% |
| **F1-Macro** | 0.6713 | **ğŸ† 0.8152** | 0.7873 |
| **Status** | âœ… Completed | âœ… **Production Ready** | âœ… Completed |

## ğŸ¯ **Research Purpose and Knowledge Gained**

### ğŸ“š Reference Paper
Research based on the scientific paper:
**"A deep learning framework for clickbait spoiler generation and type identification"**  
*Authors: Itishree Panda, Jyoti Prakash Singh, Gayadhar Pradhan, Khushi Kumari*

### ğŸ“ Educational Purpose
This is an **educational research project** reimplemented to:

1. **ğŸ”¬ Study Modern NLP**
   - Transformer architecture and sentence embeddings (SBERT)
   - Feature engineering combining numerical + embeddings
   - Multi-class text classification with imbalanced data

2. **ğŸ“° Research Clickbait Problem**
   - Analyze 3 spoiler types: phrase (42.7%), passage (39.8%), multi (17.5%)
   - Understand social impact and automated classification methods

3. **ğŸ¤– Develop ML Skills**
   - End-to-end ML pipeline from preprocessing â†’ evaluation
   - Cross-validation, hyperparameter tuning, model comparison
   - Advanced metrics: ROC-AUC, confusion matrices, error analysis

4. **ğŸ’» Technical Practice**
   - Large-scale text data processing (4,000 samples)
   - Unicode cleaning, tokenization, embedding generation
   - Data visualization and comprehensive reporting

### âš ï¸ **Purpose Disclaimer**
**ğŸ“ IMPORTANT**: This research is conducted **solely for educational and scientific purposes**.

- âŒ **No commercial intent**
- âŒ **Not for creating harmful clickbait**
- âœ… **Goal**: Learn NLP and understand social issues
- âœ… **Applications**: Academic research, education, skill development

## ğŸ“‹ **Research Overview**

### ğŸ“Š Dataset
- **ğŸ“ Source**: SemEval-2023 Clickbait Spoiler dataset from Zenodo
- **ğŸ“ Size**: 4,000 clickbait posts (3,200 train + 800 validation)
- **ğŸ·ï¸ Spoiler Types**:
  ```
  ğŸ“ phrase  (42.7%): Short phrases
  ğŸ“„ passage (39.8%): Text passages  
  ğŸ”— multi   (17.5%): Multiple separate parts
  ```

### ğŸ† **Task 2: Spoiler Classification (âœ… Completed)**

#### ğŸ”§ **Architecture**
```
Input Features (1,541 dimensions):
â”œâ”€â”€ ğŸ“Š Numerical Features (5): post_length, spoiler_length, target_length, keywords_count, has_description
â””â”€â”€ ğŸ§  SBERT Embeddings (1,536): 4 fields Ã— 384 dims each
    â”œâ”€â”€ post_text embeddings
    â”œâ”€â”€ spoiler embeddings  
    â”œâ”€â”€ target_paragraphs embeddings
    â””â”€â”€ target_keywords embeddings
```

#### ğŸ¤– **Models Comparison**
| Model | Cross-Val Accuracy | Test Accuracy | F1-Macro | ROC-AUC |
|-------|-------------------|---------------|----------|---------|
| Random Forest | 81.2% Â± 2.3% | 82.50% | 0.6713 | 0.892 |
| **SVM** | **84.1% Â± 1.8%** | **85.50%** | **0.8152** | **0.923** |
| Logistic Regression | 82.8% Â± 2.1% | 81.87% | 0.7873 | 0.905 |

#### ğŸ“ˆ **Evaluation Metrics**
- âœ… **Accuracy, Precision, Recall, F1-score** (per-class & macro)
- âœ… **ROC-AUC curves** for multi-class
- âœ… **Confusion matrices** with normalization
- âœ… **Error analysis** (116 misclassified samples analyzed)
- âœ… **Feature importance** analysis

### ğŸš§ **Task 1: Spoiler Generation (Future Development)**
- **ğŸ¤– Model**: GPT-2 Medium fine-tuning (planned)
- **ğŸ“¥ Input**: postText + targetParagraph
- **ğŸ“¤ Output**: Generated spoiler text
- **ğŸ“Š Evaluation**: BLEU, ROUGE, BERTScore, METEOR

## ğŸ—‚ï¸ **Project Structure (Optimized)**

```
ğŸ“ NLP_CB_prj/
â”œâ”€â”€ ğŸ“ scripts/                     # ğŸ”§ All core scripts (7 files)
â”‚   â”œâ”€â”€ ğŸ“„ preprocess_data.py       # ğŸ”¨ Main data preprocessing
â”‚   â”œâ”€â”€ ğŸ“„ train_classifier.py      # ğŸš€ Train ML models
â”‚   â”œâ”€â”€ ğŸ“„ evaluate_classification.py # ğŸ“Š Comprehensive evaluation
â”‚   â”œâ”€â”€ ğŸ“„ check_system_readiness.py # âš™ï¸ System & environment check
â”‚   â”œâ”€â”€ ğŸ“„ clean_unicode_auto.py    # ğŸ§¹ Automatic Unicode cleaning
â”‚   â”œâ”€â”€ ğŸ“„ create_advanced_visualizations.py # ğŸ“ˆ Advanced charts
â”‚   â””â”€â”€ ğŸ“„ analyze_processed_data.py # ğŸ” Data analysis & reports
â”œâ”€â”€ ğŸ“ data/                        # ğŸ“Š All data files
â”‚   â”œâ”€â”€ ğŸ“ raw/                     # Original JSONL files
â”‚   â”œâ”€â”€ ğŸ“ cleaned/                 # Unicode-cleaned data
â”‚   â””â”€â”€ ğŸ“ processed/               # Processed features & embeddings
â”œâ”€â”€ ğŸ“ configs/                     # âš™ï¸ YAML configuration files
â”œâ”€â”€ ğŸ“ results/                     # ğŸ“Š Outputs & visualizations
â”‚   â”œâ”€â”€ ğŸ“ preprocessing_analysis/  # Preprocessing reports
â”‚   â””â”€â”€ ğŸ“ task2_classification/    # Model results & plots
â”œâ”€â”€ ğŸ“ models/                      # ğŸ¤– Trained model files
â”œâ”€â”€ ğŸ“„ requirements.txt             # ğŸ“¦ Dependencies
â”œâ”€â”€ ğŸ“„ README.md                    # ğŸ“– This documentation
â”œâ”€â”€ ğŸ“„ project_structure.md         # ğŸ—‚ï¸ Detailed structure guide
â””â”€â”€ ğŸ“„ ENVIRONMENT_GUIDE.md         # ğŸ› ï¸ Setup instructions
```

## ğŸš€ **Quick Start & Usage**

### 1ï¸âƒ£ **Setup Environment**
```bash
# Clone repository
git clone https://github.com/coderkhongodo/NLP_CB_prj.git
cd NLP_CB_prj

# Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows
# source venv/bin/activate    # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ **Complete Workflow Commands**

```bash
# ğŸ” 1. System Check
python scripts/check_system_readiness.py

# ğŸ§¹ 2. Data Cleaning  
python scripts/clean_unicode_auto.py

# ğŸ”¨ 3. Data Processing
python scripts/preprocess_data.py

# ğŸ“Š 4. Data Analysis
python scripts/analyze_processed_data.py

# ğŸ“ˆ 5. Advanced Visualizations
python scripts/create_advanced_visualizations.py

# ğŸš€ 6. Model Training
python scripts/train_classifier.py

# ğŸ“Š 7. Model Evaluation
python scripts/evaluate_classification.py
```

### 3ï¸âƒ£ **One-liner Full Pipeline**
```bash
python scripts/check_system_readiness.py && python scripts/clean_unicode_auto.py && python scripts/preprocess_data.py && python scripts/analyze_processed_data.py && python scripts/create_advanced_visualizations.py && python scripts/train_classifier.py && python scripts/evaluate_classification.py
```

## ğŸ“Š **Detailed Results & Analysis**

### ğŸ† **Best Model Performance (SVM)**
```
âœ… Accuracy: 85.50%
âœ… F1-Macro: 0.8152
âœ… ROC-AUC:  0.923
âœ… Cross-val: 84.1% Â± 1.8%

Per-class Performance:
â”œâ”€â”€ ğŸ“ phrase:  Precision: 0.89, Recall: 0.91, F1: 0.90
â”œâ”€â”€ ğŸ“„ passage: Precision: 0.83, Recall: 0.87, F1: 0.85  
â””â”€â”€ ğŸ”— multi:   Precision: 0.78, Recall: 0.75, F1: 0.76
```

### ğŸ“ˆ **Generated Outputs**
- ğŸ“Š **Model comparison charts** (`results/task2_classification/evaluation/model_comparison.png`)
- ğŸ“‹ **Detailed evaluation report** (`detailed_evaluation_report.json`)
- ğŸ” **Error analysis** (`error_analysis.csv` - 116 misclassified samples)
- ğŸ§  **Feature importance** analysis
- ğŸ“ˆ **Advanced visualizations** (PCA, t-SNE, confusion matrices)

## âš™ï¸ **System Requirements**

### ğŸ–¥ï¸ **Hardware**
- **ğŸ’¾ RAM**: 8GB+ (recommended: 16GB)
- **ğŸ’½ Storage**: 5GB+ free space
- **ğŸ”§ CPU**: Multi-core recommended
- **ğŸ® GPU**: Optional (CUDA support for faster processing)

### ğŸ“¦ **Software Dependencies**
```python
torch>=2.0.0           # ğŸ§  PyTorch for deep learning
transformers>=4.30.0   # ğŸ¤— Hugging Face Transformers  
sentence-transformers  # ğŸ§® SBERT models
scikit-learn>=1.3.0   # ğŸ¤– ML algorithms
pandas>=2.0.0         # ğŸ“Š Data manipulation
numpy>=1.24.0         # ğŸ”¢ Numerical computing
matplotlib>=3.7.0     # ğŸ“ˆ Plotting
seaborn>=0.12.0       # ğŸ“Š Statistical visualization
```

## ğŸ”§ **Configuration Files**

### ğŸ“„ `configs/spoiler_classification_config.yaml`
```yaml
# ML model parameters
models:
  random_forest:
    n_estimators: 100
    max_depth: 10
  svm:
    C: 1.0
    kernel: 'rbf'
  logistic_regression:
    C: 1.0
    max_iter: 1000
```

### ğŸ“„ `configs/data_config.yaml`
```yaml
# Data processing configuration
data_paths:
  raw_train: "data/raw/train.jsonl"
  raw_validation: "data/raw/validation.jsonl"
sbert_model: "all-MiniLM-L6-v2"
max_length: 512
```

## ğŸ¤ **Contributing & Extension Ideas**

This project serves educational purposes. Extension ideas:

1. **ğŸ”® Task 1 Implementation**
   - GPT-2 Medium fine-tuning for spoiler generation
   - BLEU, ROUGE, BERTScore evaluation

2. **ğŸ¤– More ML Models**
   - Naive Bayes, KNN, Decision Tree
   - Deep learning: BERT, RoBERTa fine-tuning
   - Ensemble methods

3. **ğŸ“Š Advanced Analysis**
   - A/B testing framework
   - Bias analysis for different spoiler types
   - Real-time prediction API

4. **ğŸ”§ Engineering Improvements**
   - Docker containerization
   - CI/CD pipeline
   - Model versioning with MLflow

## ğŸ“ **Citation**

```bibtex
@software{clickbait_spoiler_2024,
  title={Clickbait Spoiler Classification using SBERT and Machine Learning},
  author={Huá»³nh LÃ½ TÃ¢n Khoa},
  year={2024},
  url={https://github.com/coderkhongodo/NLP_CB_prj},
  note={Educational Research Project - SVM Model achieves 85.5\% accuracy}
}
```

---

## ğŸ“ **Contact & Links**

- **ğŸ‘¨â€ğŸ’» Author**: Huá»³nh LÃ½ TÃ¢n Khoa
- **ğŸ“§ Email**: huynhlytankhoa@gmail.com  
- **ğŸ”— GitHub**: [coderkhongodo/NLP_CB_prj](https://github.com/coderkhongodo/NLP_CB_prj)
- **ğŸ¯ Purpose**: Educational Research Project
- **ğŸ“œ License**: Educational Use Only

---

**â­ If this project helps your learning, please give it a star!**
