# Clickbait Spoiler Generation and Classification Research

Dá»± Ã¡n nghiÃªn cá»©u vá» sinh spoiler vÃ  phÃ¢n loáº¡i spoiler cho clickbait sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u vÃ  machine learning.

## Má»¥c Ä‘Ã­ch nghiÃªn cá»©u vÃ  kiáº¿n thá»©c Ä‘áº¡t Ä‘Æ°á»£c

### Nguá»“n tham kháº£o
NghiÃªn cá»©u nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n dá»±a trÃªn bÃ i bÃ¡o khoa há»c:
**"A deep learning framework for clickbait spoiler generation and type identification"** 
*TÃ¡c giáº£: Itishree Panda, Jyoti Prakash Singh, Gayadhar Pradhan, Khushi Kumari*

### Má»¥c Ä‘Ã­ch há»c táº­p
ÄÃ¢y lÃ  má»™t **bÃ i nghiÃªn cá»©u há»c táº­p** Ä‘Æ°á»£c thá»±c hiá»‡n láº¡i nháº±m:

1. **TÃ¬m hiá»ƒu vá» cÃ¡c mÃ´ hÃ¬nh NLP hiá»‡n Ä‘áº¡i**
   - Hiá»ƒu sÃ¢u vá» kiáº¿n trÃºc Transformer vÃ  sentence embeddings
   - NghiÃªn cá»©u SBERT (Sentence-BERT) cho text classification
   - KhÃ¡m phÃ¡ cÃ¡c ká»¹ thuáº­t feature engineering vá»›i embeddings

2. **NghiÃªn cá»©u váº¥n Ä‘á» clickbait trong truyá»n thÃ´ng**
   - PhÃ¢n tÃ­ch hiá»‡n tÆ°á»£ng clickbait vÃ  tÃ¡c Ä‘á»™ng xÃ£ há»™i
   - Hiá»ƒu cÃ¡c loáº¡i spoiler: phrase (cá»¥m tá»«), passage (Ä‘oáº¡n), multi (nhiá»u pháº§n)
   - NghiÃªn cá»©u phÆ°Æ¡ng phÃ¡p tá»± Ä‘á»™ng phÃ¢n loáº¡i spoiler

3. **PhÃ¡t triá»ƒn ká»¹ nÄƒng Machine Learning**
   - Thá»±c hÃ nh quy trÃ¬nh ML end-to-end tá»« preprocessing Ä‘áº¿n evaluation
   - So sÃ¡nh hiá»‡u suáº¥t cÃ¡c thuáº­t toÃ¡n machine learning
   - Ãp dá»¥ng cÃ¡c metrics Ä‘Ã¡nh giÃ¡ phÃ¹ há»£p cho multi-class classification

4. **Kiáº¿n thá»©c ká»¹ thuáº­t Ä‘áº¡t Ä‘Æ°á»£c**
   - Xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n quy mÃ´ lá»›n vá»›i pandas vÃ  numpy
   - Ká»¹ thuáº­t tokenization vÃ  text preprocessing
   - Feature engineering káº¿t há»£p numerical features vÃ  embeddings
   - Cross-validation vÃ  hyperparameter tuning
   - Data visualization vÃ  phÃ¢n tÃ­ch káº¿t quáº£

### TuyÃªn bá»‘ vá» má»¥c Ä‘Ã­ch
**âš ï¸ QUAN TRá»ŒNG**: NghiÃªn cá»©u nÃ y Ä‘Æ°á»£c thá»±c hiá»‡n **chá»‰ vá»›i má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u khoa há»c**. 

- **KhÃ´ng cÃ³ má»¥c Ä‘Ã­ch thÆ°Æ¡ng máº¡i**
- **KhÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o clickbait cÃ³ háº¡i**
- **Má»¥c tiÃªu**: Hiá»ƒu biáº¿t sÃ¢u hÆ¡n vá» NLP vÃ  cÃ¡c váº¥n Ä‘á» xÃ£ há»™i liÃªn quan
- **á»¨ng dá»¥ng**: NghiÃªn cá»©u há»c thuáº­t, giÃ¡o dá»¥c, vÃ  phÃ¡t triá»ƒn ká»¹ nÄƒng ká»¹ thuáº­t

## Tá»•ng quan nghiÃªn cá»©u

### Bá»™ dá»¯ liá»‡u
- **Nguá»“n**: SemEval-2023 Clickbait Spoiler dataset tá»« Zenodo
- **KÃ­ch thÆ°á»›c**: 4.000 bÃ i Ä‘Äƒng clickbait
- **PhÃ¢n chia**: 3.200 máº«u huáº¥n luyá»‡n, 800 máº«u validation
- **Loáº¡i spoiler**: 
  - **phrase** (42.7%): Cá»¥m tá»« ngáº¯n
  - **passage** (39.8%): Äoáº¡n vÄƒn báº£n
  - **multi** (17.5%): Nhiá»u pháº§n riÃªng biá»‡t

### PhÆ°Æ¡ng phÃ¡p Ä‘Ã£ implement

#### Task 2: PhÃ¢n loáº¡i loáº¡i spoiler (ÄÃ£ hoÃ n thÃ nh)
- **MÃ´ hÃ¬nh**: SBERT + Machine Learning Classifiers
- **Äáº·c trÆ°ng**: 
  - 5 numerical features (post_length, spoiler_length, target_length, keywords_count, has_description)
  - 4 SBERT embeddings (384-dim má»—i field): post_text, spoiler, target_paragraphs, target_keywords
  - **Tá»•ng**: 1541 features (5 + 384Ã—4 = 1541)
- **Bá»™ phÃ¢n loáº¡i so sÃ¡nh**: 3 models
  - Random Forest (RF)
  - Support Vector Machine (SVM)
  - Logistic Regression (LR)
- **ÄÃ¡nh giÃ¡**: Accuracy, Precision, Recall, F1-score, ROC-AUC, Confusion Matrix

#### Task 1: Táº¡o spoiler (Sáº½ cáº­p nháº­t sau)
- **MÃ´ hÃ¬nh**: GPT-2 Medium (dá»± Ä‘á»‹nh implement)
- **Äáº§u vÃ o**: postText + targetParagraph  
- **Äáº§u ra**: VÄƒn báº£n spoiler
- **ÄÃ¡nh giÃ¡**: BLEU, ROUGE, BERTScore, METEOR

## Cáº¥u trÃºc Project

```
clickbait-spoiler-research/
â”œâ”€â”€ data/                           # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                       # Dá»¯ liá»‡u gá»‘c (train.jsonl, validation.jsonl)
â”‚   â”œâ”€â”€ cleaned/                   # Dá»¯ liá»‡u Ä‘Ã£ clean unicode
â”‚   â”œâ”€â”€ processed/                 # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚   â””â”€â”€ backup/                    # Backup dá»¯ liá»‡u
â”œâ”€â”€ src/                           # MÃ£ nguá»“n chÃ­nh
â”‚   â”œâ”€â”€ data/                      # Data processing modules
â”‚   â”œâ”€â”€ models/                    # Model definitions
â”‚   â”œâ”€â”€ training/                  # Training scripts
â”‚   â”œâ”€â”€ evaluation/                # Evaluation scripts
â”‚   â””â”€â”€ utils/                     # Utility functions
â”œâ”€â”€ scripts/                       # Scripts thá»±c thi
â”‚   â”œâ”€â”€ data_exploration.py        # KhÃ¡m phÃ¡ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ preprocess_data.py         # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ check_environment.py       # Kiá»ƒm tra mÃ´i trÆ°á»ng
â”‚   â””â”€â”€ setup_project.py           # Thiáº¿t láº­p project
â”œâ”€â”€ configs/                       # Configuration files
â”‚   â”œâ”€â”€ data_config.yaml          # Cáº¥u hÃ¬nh dá»¯ liá»‡u
â”‚   â””â”€â”€ spoiler_classification_config.yaml  # Cáº¥u hÃ¬nh phÃ¢n loáº¡i
â”œâ”€â”€ results/                       # Káº¿t quáº£ thÃ­ nghiá»‡m
â”‚   â”œâ”€â”€ data_exploration/          # Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch dá»¯ liá»‡u
â”‚   â”œâ”€â”€ task2_classification/      # Káº¿t quáº£ phÃ¢n loáº¡i
â”‚   â””â”€â”€ preprocessing_analysis/    # PhÃ¢n tÃ­ch tiá»n xá»­ lÃ½
â”œâ”€â”€ models/                        # MÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
â”œâ”€â”€ logs/                          # Log files
â””â”€â”€ venv/                          # Virtual environment
```

## CÃ i Ä‘áº·t vÃ  thiáº¿t láº­p

### 1. YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- RAM: 8GB+ (recommended 16GB)
- Storage: 5GB+ free space

### 2. Thiáº¿t láº­p mÃ´i trÆ°á»ng
```bash
# Táº¡o virtual environment
python -m venv venv

# KÃ­ch hoáº¡t (Windows)
.\venv\Scripts\Activate.ps1

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 3. Kiá»ƒm tra mÃ´i trÆ°á»ng
```bash
python scripts/check_environment.py
```

## Sá»­ dá»¥ng

### 1. KhÃ¡m phÃ¡ dá»¯ liá»‡u
```bash
python scripts/data_exploration.py
```
- Táº¡o cÃ¡c biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch trong `results/data_exploration/`
- Thá»‘ng kÃª chi tiáº¿t vá» bá»™ dá»¯ liá»‡u

### 2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
```bash
python scripts/preprocess_data.py
```
- Clean unicode characters
- Táº¡o numerical features
- Sinh SBERT embeddings
- LÆ°u dá»¯ liá»‡u processed trong `data/processed/`

### 3. Huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i
```bash
python src/training/train_classifier.py
```
- Huáº¥n luyá»‡n 3 models vá»›i cross-validation
- LÆ°u models trong `models/task2_classification/`
- Táº¡o bÃ¡o cÃ¡o káº¿t quáº£ trong `results/task2_classification/`

### 4. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
```bash
python src/evaluation/evaluate_classification.py
```
- So sÃ¡nh hiá»‡u suáº¥t cÃ¡c models
- Táº¡o confusion matrices vÃ  biá»ƒu Ä‘á»“
- PhÃ¢n tÃ­ch feature importance

## Káº¿t quáº£ hiá»‡n táº¡i

### PhÃ¢n loáº¡i spoiler (Task 2)
âœ… **ÄÃ£ hoÃ n thÃ nh vÃ  Ä‘Ã¡nh giÃ¡**
- So sÃ¡nh 3 bá»™ phÃ¢n loáº¡i: Random Forest, SVM, Logistic Regression
- Features: 1541-dimensional (5 numerical + 1536 embeddings)
- Evaluation metrics: Accuracy, Precision, Recall, F1-score, ROC-AUC
- Visualizations: Confusion matrices, feature importance, model comparison

### Táº¡o spoiler (Task 1)
ğŸ”„ **Äang phÃ¡t triá»ƒn**
- Sáº½ implement GPT-2 Medium fine-tuning
- Text generation vá»›i BLEU, ROUGE evaluation

## Files cáº¥u hÃ¬nh

### `configs/spoiler_classification_config.yaml`
- Cáº¥u hÃ¬nh 3 ML models (RF, SVM, LR)
- Parameters cho training vÃ  evaluation
- Feature configuration

### `configs/data_config.yaml`
- ÄÆ°á»ng dáº«n dá»¯ liá»‡u
- Text processing parameters
- SBERT model configuration

## Dependencies chÃ­nh

```txt
torch>=2.0.0           # PyTorch cho deep learning
transformers>=4.30.0   # Hugging Face Transformers
sentence-transformers  # SBERT models
scikit-learn>=1.3.0   # Machine learning algorithms
pandas>=2.0.0         # Data manipulation
numpy>=1.24.0         # Numerical computing
matplotlib>=3.7.0     # Plotting
seaborn>=0.12.0       # Statistical visualization
```

Xem file `requirements.txt` Ä‘á»ƒ biáº¿t danh sÃ¡ch Ä‘áº§y Ä‘á»§.

## CÃ¡ch Ä‘Ã³ng gÃ³p

Dá»± Ã¡n nÃ y phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c táº­p. Náº¿u muá»‘n má»Ÿ rá»™ng:
1. Implement Task 1 (spoiler generation) vá»›i GPT-2
2. ThÃªm cÃ¡c bá»™ phÃ¢n loáº¡i khÃ¡c (Naive Bayes, KNN, Decision Tree, etc.)
3. Thá»­ nghiá»‡m vá»›i cÃ¡c pre-trained models khÃ¡c
4. Cáº£i thiá»‡n feature engineering

## TrÃ­ch dáº«n

```bibtex
@article{clickbait_spoiler_2024,
  title={Clickbait Spoiler Generation and Classification using GPT-2 and SBERT: A Deep Learning Study},
  author={Huá»³nh LÃ½ TÃ¢n Khoa},
  email={huynhlytankhoa@gmail.com},
  type={Academic Research Project}
}
```

---

**ğŸ“§ Contact**: huynhlytankhoa@gmail.com  
**ğŸ¯ Purpose**: Educational Research Project  
