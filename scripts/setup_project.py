#!/usr/bin/env python3
"""
Script setup ban ƒë·∫ßu cho project nghi√™n c·ª©u clickbait spoiler
"""

import os
import json
import pandas as pd
from pathlib import Path

def create_directories():
    """T·∫°o c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt n·∫øu ch∆∞a t·ªìn t·∫°i"""
    directories = [
        "data/raw",
        "data/processed", 
        "data/splits",
        "models/spoiler_generator",
        "models/spoiler_classifier",
        "logs/spoiler_generation",
        "logs/spoiler_classification", 
        "results/spoiler_generation",
        "results/spoiler_classification",
        "data/processed/embeddings"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Created directory: {directory}")

def check_data_files():
    """Ki·ªÉm tra xem c√°c file d·ªØ li·ªáu c√≥ t·ªìn t·∫°i kh√¥ng"""
    data_files = {
        "data/raw/train.jsonl": "Training data",
        "data/raw/validation.jsonl": "Validation data", 
        "data/raw/README.md": "Dataset documentation"
    }
    
    print("\nüìä Checking data files:")
    for file_path, description in data_files.items():
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / (1024 * 1024)
            print(f"‚úÖ {description}: {file_path} ({size_mb:.1f} MB)")
        else:
            print(f"‚ùå {description}: {file_path} - NOT FOUND")

def explore_data_sample():
    """Kh√°m ph√° m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n"""
    train_file = "data/raw/train.jsonl"
    
    if not os.path.exists(train_file):
        print("‚ùå Training data not found!")
        return
        
    print("\nüîç Exploring sample data:")
    print("-" * 50)
    
    # ƒê·ªçc 5 d√≤ng ƒë·∫ßu ti√™n
    with open(train_file, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 3:  # Ch·ªâ xem 3 m·∫´u ƒë·∫ßu
                break
            
            data = json.loads(line)
            print(f"\nüìù Sample {i+1}:")
            print(f"UUID: {data.get('uuid', 'N/A')}")
            print(f"Post Text: {data.get('postText', 'N/A')[:100]}...")
            print(f"Target Title: {data.get('targetTitle', 'N/A')[:100]}...")
            print(f"Spoiler: {data.get('spoiler', 'N/A')[:100]}...")
            print(f"Tags: {data.get('tags', 'N/A')}")
    
    # ƒê·∫øm t·ªïng s·ªë d√≤ng
    with open(train_file, 'r', encoding='utf-8') as f:
        total_lines = sum(1 for _ in f)
    print(f"\nüìä Total training samples: {total_lines}")

def create_initial_notebook():
    """T·∫°o notebook kh√°m ph√° d·ªØ li·ªáu ƒë·∫ßu ti√™n"""
    notebook_content = {
        "cells": [
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "# Clickbait Spoiler Data Exploration\n",
                    "\n",
                    "Notebook n√†y d√πng ƒë·ªÉ kh√°m ph√° v√† ph√¢n t√≠ch b·ªô d·ªØ li·ªáu clickbait spoiler t·ª´ SemEval-2023.\n",
                    "\n",
                    "## Overview\n",
                    "- **Dataset**: SemEval-2023 Clickbait Spoiling\n", 
                    "- **Task 1**: Spoiler Generation (GPT-2)\n",
                    "- **Task 2**: Spoiler Type Classification (SBERT + ML)\n"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "source": [
                    "import json\n",
                    "import pandas as pd\n",
                    "import matplotlib.pyplot as plt\n",
                    "import seaborn as sns\n",
                    "from collections import Counter\n",
                    "\n",
                    "# Set style\n",
                    "plt.style.use('seaborn-v0_8')\n",
                    "sns.set_palette('husl')"
                ]
            },
            {
                "cell_type": "code",
                "execution_count": None,
                "metadata": {},
                "source": [
                    "# Load training data\n",
                    "def load_jsonl(file_path):\n",
                    "    data = []\n",
                    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
                    "        for line in f:\n",
                    "            data.append(json.loads(line))\n",
                    "    return data\n",
                    "\n",
                    "train_data = load_jsonl('../data/raw/train.jsonl')\n",
                    "val_data = load_jsonl('../data/raw/validation.jsonl')\n",
                    "\n",
                    "print(f\"Training samples: {len(train_data)}\")\n",
                    "print(f\"Validation samples: {len(val_data)}\")"
                ]
            },
            {
                "cell_type": "markdown",
                "metadata": {},
                "source": ["## Data Analysis\n", "Ph√¢n t√≠ch c·∫•u tr√∫c v√† ph√¢n ph·ªëi d·ªØ li·ªáu"]
            }
        ],
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python", 
                "name": "python3"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    notebook_path = "notebooks/01_data_exploration.ipynb"
    with open(notebook_path, 'w', encoding='utf-8') as f:
        json.dump(notebook_content, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Created notebook: {notebook_path}")

def main():
    print("üöÄ Setting up Clickbait Spoiler Research Project...")
    print("=" * 60)
    
    # T·∫°o th∆∞ m·ª•c
    create_directories()
    
    # Ki·ªÉm tra d·ªØ li·ªáu
    check_data_files()
    
    # Kh√°m ph√° d·ªØ li·ªáu m·∫´u
    explore_data_sample()
    
    # T·∫°o notebook
    create_initial_notebook()
    
    print("\n" + "=" * 60)
    print("üéâ Project setup completed!")
    print("\nüìã Next steps:")
    print("1. Run: jupyter lab")
    print("2. Open: notebooks/01_data_exploration.ipynb")
    print("3. Explore the dataset and understand the structure")
    print("4. Implement model classes in src/")
    
if __name__ == "__main__":
    main() 