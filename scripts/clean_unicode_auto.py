#!/usr/bin/env python3
"""
Script t·ª± ƒë·ªông ƒë·ªÉ ph√°t hi·ªán v√† l√†m s·∫°ch c√°c k√Ω t·ª± Unicode ambiguous trong d·ªØ li·ªáu JSONL
(Phi√™n b·∫£n kh√¥ng c·∫ßn t∆∞∆°ng t√°c - t·ª± ƒë·ªông thay th·∫ø file g·ªëc)
"""

import json
import re
import unicodedata
from pathlib import Path
from collections import defaultdict
import shutil

# Danh s√°ch c√°c k√Ω t·ª± Unicode problematic
PROBLEMATIC_CHARS = {
    # Zero-width characters
    '\u200b': '',  # Zero Width Space
    '\u200c': '',  # Zero Width Non-Joiner
    '\u200d': '',  # Zero Width Joiner
    '\u200e': '',  # Left-to-Right Mark
    '\u200f': '',  # Right-to-Left Mark
    '\u2060': '',  # Word Joiner
    '\ufeff': '',  # Byte Order Mark / Zero Width No-Break Space
    
    # Control characters
    '\u0000': '',  # NULL
    '\u0001': '',  # Start of Heading
    '\u0002': '',  # Start of Text
    '\u0003': '',  # End of Text
    '\u0004': '',  # End of Transmission
    '\u0005': '',  # Enquiry
    '\u0006': '',  # Acknowledge
    '\u0007': '',  # Bell
    '\u0008': '',  # Backspace
    '\u000b': '',  # Vertical Tab
    '\u000c': '',  # Form Feed
    '\u000e': '',  # Shift Out
    '\u000f': '',  # Shift In
    '\u0010': '',  # Data Link Escape
    '\u0011': '',  # Device Control One
    '\u0012': '',  # Device Control Two
    '\u0013': '',  # Device Control Three
    '\u0014': '',  # Device Control Four
    '\u0015': '',  # Negative Acknowledge
    '\u0016': '',  # Synchronous Idle
    '\u0017': '',  # End of Transmission Block
    '\u0018': '',  # Cancel
    '\u0019': '',  # End of Medium
    '\u001a': '',  # Substitute
    '\u001b': '',  # Escape
    '\u001c': '',  # File Separator
    '\u001d': '',  # Group Separator
    '\u001e': '',  # Record Separator
    '\u001f': '',  # Unit Separator
    '\u007f': '',  # Delete
    
    # Common homoglyphs (k√Ω t·ª± tr√¥ng gi·ªëng nhau)
    '\u2010': '-',  # Hyphen ‚Üí ASCII Hyphen
    '\u2011': '-',  # Non-breaking Hyphen ‚Üí ASCII Hyphen
    '\u2012': '-',  # Figure Dash ‚Üí ASCII Hyphen
    '\u2013': '-',  # En Dash ‚Üí ASCII Hyphen
    '\u2014': '-',  # Em Dash ‚Üí ASCII Hyphen
    '\u2015': '-',  # Horizontal Bar ‚Üí ASCII Hyphen
    '\u2212': '-',  # Minus Sign ‚Üí ASCII Hyphen
    
    # Quotation marks
    '\u2018': "'",  # Left Single Quotation Mark ‚Üí ASCII Apostrophe
    '\u2019': "'",  # Right Single Quotation Mark ‚Üí ASCII Apostrophe
    '\u201a': "'",  # Single Low-9 Quotation Mark ‚Üí ASCII Apostrophe
    '\u201b': "'",  # Single High-Reversed-9 Quotation Mark ‚Üí ASCII Apostrophe
    '\u201c': '"',  # Left Double Quotation Mark ‚Üí ASCII Quote
    '\u201d': '"',  # Right Double Quotation Mark ‚Üí ASCII Quote
    '\u201e': '"',  # Double Low-9 Quotation Mark ‚Üí ASCII Quote
    '\u201f': '"',  # Double High-Reversed-9 Quotation Mark ‚Üí ASCII Quote
    '\u2039': '<',  # Single Left-Pointing Angle Quotation Mark
    '\u203a': '>',  # Single Right-Pointing Angle Quotation Mark
    '\u00ab': '"',  # Left-Pointing Double Angle Quotation Mark
    '\u00bb': '"',  # Right-Pointing Double Angle Quotation Mark
    
    # Spaces
    '\u00a0': ' ',  # Non-Breaking Space ‚Üí ASCII Space
    '\u2000': ' ',  # En Quad ‚Üí ASCII Space
    '\u2001': ' ',  # Em Quad ‚Üí ASCII Space
    '\u2002': ' ',  # En Space ‚Üí ASCII Space
    '\u2003': ' ',  # Em Space ‚Üí ASCII Space
    '\u2004': ' ',  # Three-Per-Em Space ‚Üí ASCII Space
    '\u2005': ' ',  # Four-Per-Em Space ‚Üí ASCII Space
    '\u2006': ' ',  # Six-Per-Em Space ‚Üí ASCII Space
    '\u2007': ' ',  # Figure Space ‚Üí ASCII Space
    '\u2008': ' ',  # Punctuation Space ‚Üí ASCII Space
    '\u2009': ' ',  # Thin Space ‚Üí ASCII Space
    '\u200a': ' ',  # Hair Space ‚Üí ASCII Space
    '\u2028': ' ',  # Line Separator ‚Üí ASCII Space
    '\u2029': ' ',  # Paragraph Separator ‚Üí ASCII Space
    '\u202f': ' ',  # Narrow No-Break Space ‚Üí ASCII Space
    '\u205f': ' ',  # Medium Mathematical Space ‚Üí ASCII Space
    '\u3000': ' ',  # Ideographic Space ‚Üí ASCII Space
    
    # Other common problematic characters
    '\u00ad': '',   # Soft Hyphen ‚Üí Remove
    '\u034f': '',   # Combining Grapheme Joiner ‚Üí Remove
    '\u061c': '',   # Arabic Letter Mark ‚Üí Remove
    '\u180e': '',   # Mongolian Vowel Separator ‚Üí Remove
}

def detect_problematic_chars(text):
    """Ph√°t hi·ªán c√°c k√Ω t·ª± problematic trong text"""
    found_chars = {}
    for char in text:
        if char in PROBLEMATIC_CHARS:
            if char not in found_chars:
                found_chars[char] = 0
            found_chars[char] += 1
    return found_chars

def clean_text(text):
    """L√†m s·∫°ch text b·∫±ng c√°ch thay th·∫ø c√°c k√Ω t·ª± problematic"""
    if not isinstance(text, str):
        return text, {}
    
    cleaned = text
    changes_made = {}
    
    # Thay th·∫ø c√°c k√Ω t·ª± problematic
    for problematic_char, replacement in PROBLEMATIC_CHARS.items():
        if problematic_char in cleaned:
            count = cleaned.count(problematic_char)
            cleaned = cleaned.replace(problematic_char, replacement)
            changes_made[problematic_char] = count
    
    # Normalize Unicode (NFC normalization)
    cleaned = unicodedata.normalize('NFC', cleaned)
    
    # Remove duplicate spaces
    cleaned = re.sub(r'\s+', ' ', cleaned)
    
    # Strip leading/trailing whitespace
    cleaned = cleaned.strip()
    
    return cleaned, changes_made

def clean_json_object(obj):
    """L√†m s·∫°ch object JSON recursively"""
    total_changes = defaultdict(int)
    
    if isinstance(obj, str):
        cleaned, changes = clean_text(obj)
        for char, count in changes.items():
            total_changes[char] += count
        return cleaned, total_changes
    
    elif isinstance(obj, list):
        cleaned_list = []
        for item in obj:
            cleaned_item, changes = clean_json_object(item)
            cleaned_list.append(cleaned_item)
            for char, count in changes.items():
                total_changes[char] += count
        return cleaned_list, total_changes
    
    elif isinstance(obj, dict):
        cleaned_dict = {}
        for key, value in obj.items():
            # Clean key
            cleaned_key, key_changes = clean_json_object(key)
            for char, count in key_changes.items():
                total_changes[char] += count
            
            # Clean value
            cleaned_value, value_changes = clean_json_object(value)
            for char, count in value_changes.items():
                total_changes[char] += count
            
            cleaned_dict[cleaned_key] = cleaned_value
        return cleaned_dict, total_changes
    
    else:
        return obj, total_changes

def analyze_file(file_path):
    """Ph√¢n t√≠ch file ƒë·ªÉ t√¨m c√°c k√Ω t·ª± problematic"""
    print(f"üîç Ph√¢n t√≠ch file: {file_path}")
    
    total_chars_found = defaultdict(int)
    total_lines = 0
    problematic_lines = 0
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                total_lines += 1
                try:
                    data = json.loads(line.strip())
                    found_chars = {}
                    
                    # Scan all text fields recursively
                    def scan_object(obj):
                        if isinstance(obj, str):
                            chars = detect_problematic_chars(obj)
                            for char, count in chars.items():
                                found_chars[char] = found_chars.get(char, 0) + count
                        elif isinstance(obj, list):
                            for item in obj:
                                scan_object(item)
                        elif isinstance(obj, dict):
                            for value in obj.values():
                                scan_object(value)
                    
                    scan_object(data)
                    
                    if found_chars:
                        problematic_lines += 1
                        for char, count in found_chars.items():
                            total_chars_found[char] += count
                
                except json.JSONDecodeError:
                    print(f"‚ùå L·ªói JSON ·ªü d√≤ng {line_num}")
    
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc file: {e}")
        return None
    
    print(f"üìä T·ªïng s·ªë d√≤ng: {total_lines}")
    print(f"‚ö†Ô∏è  D√≤ng c√≥ v·∫•n ƒë·ªÅ: {problematic_lines}")
    
    if total_chars_found:
        print("üîç K√Ω t·ª± problematic t√¨m th·∫•y:")
        for char, count in sorted(total_chars_found.items(), key=lambda x: x[1], reverse=True)[:10]:  # Top 10
            char_name = unicodedata.name(char, f"U+{ord(char):04X}")
            print(f"  '{char}' (U+{ord(char):04X} - {char_name}): {count} l·∫ßn")
        
        if len(total_chars_found) > 10:
            print(f"  ... v√† {len(total_chars_found) - 10} lo·∫°i k√Ω t·ª± kh√°c")
    else:
        print("‚úÖ Kh√¥ng t√¨m th·∫•y k√Ω t·ª± problematic")
    
    return total_chars_found

def clean_file_inplace(file_path):
    """L√†m s·∫°ch file v√† thay th·∫ø file g·ªëc"""
    print(f"üßπ L√†m s·∫°ch file: {file_path}")
    
    total_changes = defaultdict(int)
    total_lines = 0
    cleaned_lines = 0
    temp_file = f"{file_path}.temp"
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f_in, \
             open(temp_file, 'w', encoding='utf-8') as f_out:
            
            for line_num, line in enumerate(f_in, 1):
                total_lines += 1
                try:
                    data = json.loads(line.strip())
                    cleaned_data, changes = clean_json_object(data)
                    
                    if changes:
                        cleaned_lines += 1
                        for char, count in changes.items():
                            total_changes[char] += count
                    
                    # Write cleaned data
                    json_line = json.dumps(cleaned_data, ensure_ascii=False, separators=(',', ':'))
                    f_out.write(json_line + '\n')
                
                except json.JSONDecodeError as e:
                    print(f"‚ùå L·ªói JSON ·ªü d√≤ng {line_num}: {e}")
                    # Write original line if can't parse
                    f_out.write(line)
        
        # Replace original file with cleaned file
        shutil.move(temp_file, file_path)
        
    except Exception as e:
        print(f"‚ùå L·ªói x·ª≠ l√Ω file: {e}")
        # Clean up temp file if error
        if Path(temp_file).exists():
            Path(temp_file).unlink()
        return None
    
    print(f"üìä T·ªïng s·ªë d√≤ng x·ª≠ l√Ω: {total_lines}")
    print(f"üîß D√≤ng ƒë√£ s·ª≠a: {cleaned_lines}")
    
    if total_changes:
        print("‚ú® Thay ƒë·ªïi ƒë√£ th·ª±c hi·ªán:")
        top_changes = sorted(total_changes.items(), key=lambda x: x[1], reverse=True)[:10]
        for char, count in top_changes:
            char_name = unicodedata.name(char, f"U+{ord(char):04X}")
            replacement = PROBLEMATIC_CHARS.get(char, '')
            print(f"  '{char}' ‚Üí '{replacement}': {count} l·∫ßn")
        
        if len(total_changes) > 10:
            remaining = sum(total_changes.values()) - sum(count for _, count in top_changes)
            print(f"  ... v√† {remaining} thay ƒë·ªïi kh√°c")
    else:
        print("‚úÖ Kh√¥ng c√≥ thay ƒë·ªïi n√†o ƒë∆∞·ª£c th·ª±c hi·ªán")
    
    return total_changes

def create_backup(file_path):
    """T·∫°o backup c·ªßa file g·ªëc"""
    backup_dir = Path("data/backup")
    backup_dir.mkdir(parents=True, exist_ok=True)
    
    backup_path = backup_dir / f"{Path(file_path).name}.backup"
    
    try:
        shutil.copy2(file_path, backup_path)
        print(f"üíæ ƒê√£ t·∫°o backup: {backup_path}")
        return backup_path
    except Exception as e:
        print(f"‚ùå Kh√¥ng th·ªÉ t·∫°o backup: {e}")
        return None

def main():
    """H√†m ch√≠nh"""
    print("üîß C√îNG C·ª§ L√ÄM S·∫†CH K√ù T·ª∞ UNICODE AMBIGUOUS (T·ª∞ ƒê·ªòNG)")
    print("=" * 60)
    
    # Files to process
    files_to_process = [
        "data/raw/train.jsonl",
        "data/raw/validation.jsonl"
    ]
    
    summary_report = []
    
    for file_path in files_to_process:
        if not Path(file_path).exists():
            print(f"‚ö†Ô∏è  File kh√¥ng t·ªìn t·∫°i: {file_path}")
            continue
        
        print(f"\n{'='*60}")
        print(f"üìÅ X·ª≠ l√Ω file: {file_path}")
        print(f"{'='*60}")
        
        # 1. Ph√¢n t√≠ch file g·ªëc
        problematic_chars = analyze_file(file_path)
        
        if problematic_chars:
            # 2. T·∫°o backup
            backup_path = create_backup(file_path)
            
            # 3. L√†m s·∫°ch file (in-place)
            changes = clean_file_inplace(file_path)
            
            if changes:
                # 4. Verify cleaned file
                print(f"\nüîç Ki·ªÉm tra file ƒë√£ l√†m s·∫°ch...")
                verify_chars = analyze_file(file_path)
                
                if not verify_chars:
                    print("‚úÖ File ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch th√†nh c√¥ng!")
                    summary_report.append({
                        'file': file_path,
                        'status': 'success',
                        'changes': sum(changes.values()),
                        'backup': backup_path
                    })
                else:
                    print("‚ö†Ô∏è  V·∫´n c√≤n k√Ω t·ª± problematic sau khi l√†m s·∫°ch!")
                    summary_report.append({
                        'file': file_path,
                        'status': 'partial',
                        'changes': sum(changes.values()),
                        'backup': backup_path
                    })
            else:
                print("‚úÖ Kh√¥ng c√≥ thay ƒë·ªïi n√†o ƒë∆∞·ª£c th·ª±c hi·ªán")
                summary_report.append({
                    'file': file_path,
                    'status': 'no_changes',
                    'changes': 0,
                    'backup': backup_path
                })
        else:
            print("‚úÖ File ƒë√£ s·∫°ch, kh√¥ng c·∫ßn x·ª≠ l√Ω")
            summary_report.append({
                'file': file_path,
                'status': 'clean',
                'changes': 0,
                'backup': None
            })
    
    # T·∫°o b√°o c√°o t·ªïng k·∫øt
    print(f"\n{'='*60}")
    print("üìã B√ÅO C√ÅO T·ªîNG K·∫æT")
    print(f"{'='*60}")
    
    for report in summary_report:
        print(f"\nüìÅ File: {report['file']}")
        print(f"   Tr·∫°ng th√°i: {report['status']}")
        print(f"   Thay ƒë·ªïi: {report['changes']} k√Ω t·ª±")
        if report['backup']:
            print(f"   Backup: {report['backup']}")
    
    total_changes = sum(report['changes'] for report in summary_report)
    print(f"\nüéâ HO√ÄN TH√ÄNH! T·ªïng c·ªông {total_changes} thay ƒë·ªïi ƒë∆∞·ª£c th·ª±c hi·ªán.")
    print("üìÅ C√°c file backup ƒë∆∞·ª£c l∆∞u trong: data/backup/")

if __name__ == "__main__":
    main() 